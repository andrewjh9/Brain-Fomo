#!/bin/bash

#SBATCH --partition=gpu_a100
#SBATCH --gpus=1
#SBATCH --job-name=res_6_vqnsp_tuev
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=9
#SBATCH --time=24:00:00
#SBATCH --output=output/res_6_vqnsp_tuev_%x_%j.out

module purge
module load 2023

echo "--- Environment After Loading Modules ---"
echo "Loaded modules:"
module list
echo "----------------------------------------"
echo "CUDA_HOME is set to: $CUDA_HOME"
echo "Path to nvcc: $(which nvcc)"
echo "----------------------------------------"

export PATH="$HOME/miniconda3/bin:$PATH"
eval "$(conda shell.bash hook)"

conda activate labram_pretrain
echo "Activated conda environment: $CONDA_DEFAULT_ENV"
echo "Python version: $(python --version)"
echo "Python path: $(which python)"
echo "Pip path: $(which pip3)"

echo "--- Checking PyTorch GPU Access ---"
srun python -uc "import torch; print(f'PyTorch version: {torch.__version__}'); print(f'CUDA available? {torch.cuda.is_available()}'); print(f'CUDA version built with: {torch.version.cuda}'); print(f'Device name: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else None}')"
echo "---------------------------------"

cd $HOME
cd ../../
echo "[$(date)] Using dir: $(pwd)"

FILEPATH="home/scur0546/pretraining/run_vqnsp_training.py"

echo "Torchrun path: $(which torchrun)"


echo "[$(date)] Running file: $FILEPATH"

export OMP_NUM_THREADS=1

srun torchrun --nnodes=1 --nproc_per_node=1 "$FILEPATH" \
    --output_dir home/scur0546/pretraining/checkpoints/res_6_vqnsp_tuev/ \
    --log_dir home/scur0546/pretraining/log/res_6_vqnsp_tuev/ \
    --model vqnsp_encoder_base_decoder_3x200x12 \
    --codebook_n_emd 8192 \
    --codebook_emd_dim 64 \
    --quantize_kmeans_init \
    --batch_size 128 \
    --opt adamw \
    --opt_betas 0.9 0.99 \
    --weight_decay 1e-4  \
    --warmup_epochs 5 \
    --epochs 20 \
    --save_ckpt_freq 20 \
    --res_quant